\chapter{Approach}
\label{chap:approach}

\section{Overview}
\section{Creating Temporal database}
\subsection{Auditing}
\subsection{Large query handling On the Audit Tables}
In proposition 1, we showed that reconstructing a snapshot table and computing the latest version of a particular record at a timestamp of interest by using a temporal audit table is a linear time process with time complexity of approximately $\mathcal{O}(t)$. Therefore, in the presence of multiple and concurrent queries on the temporal database, such transactions are computationally expensive and inefficient.

In this section we demonstrate a practical solution to handle large query workloads on the append-only temporal audit tables by materializing $n$ number of precomputed snapshots at optimal timestamps. Using precomputed materialized view is proven to be effective in [cite][cite] We also show that with varying query load, we can dynamically adjust snapshots in order to always have the optimal position on the timeline for the precomputed snapshots.

\textbf{Definition. (Query Answering Using Snapshots)}: Let $Q^T(T)$ be the query on a temporal database $D^T$. We argue that precomputing $snapshot(r,t)$ using the method described in Definition 5, and use it as the materialized view to answer $Q(t)$, can decrease the computational cost.

\textbf{proposition}: Suppose there is a materialized precomputed $snapshot(r,s)$ available on the timeline, then queries and subsequent $snapshot(r,t)$ could be calculated with complexity:
$$\mathcal{O}(|\{x: x\in r^T\mathrm{\ and\ } x.\mathrm{updates} \in [s,
t]\}|) \simeq \mathcal{O}(|s-t|)$$

\subsection{Optimal Materialization of Snapshots}
Let $T_Q = \{q_1, q_2, \dots, q_n\}$ be the timestamps of $n$ queries, each 
querying the database at $D^T(q_i)$. Our goal is to compute $m$ number of timestamps in optimal timestamps on the timeline to answer to $T_Q$ at lowest possible cost. The cost function is defined as the total query answering cost given $m$ number of precomputed snapshots.

\textbf{Cost of Query Answering}: In the presence of a single materialized precomputed snapshot at time $s$, the cost of answering the query $T_q$ is calculated as:
$$\mathrm{cost}(T_q | s) = \sum_{q\in T_q} |q - s|$$
Now if multiple snapshots at times $S=\{s_1, s_2, \dots, s_m\}$ were precomputed and materialized, then 
$$\mathrm{cost}(T_q|S) = \sum_{q\in T_q} \min\{|q-s| : s\in S\}$$

\textbf{Definition. (Optimal Snapshot placement)}: The goal is to precompute $m$ number of snapshots at optimal timestamps $S^*=\{s_1, s_2, \dots, s_m\}$ for materialization, such that 
$$cost(T_q|S^*)= Arg min(\sum_{q\in T_q}\{|q - s|:s \in S^*\})$$

We propose that the median of $T_q$ on the timeline is the best candidate to place one snapshot:

\textbf{Theorem}: Median of set of n finite points on a line, minimizes the sum of absolute deviations.

\textbf{Proof}:
Assume that there are two queries $q_1$ and $q_2$, such that $T(q_2)>T(q_1)$. for the placement of snapshot, on the timeline, there are several cases which needs to be considered.\\
\begin{large}
	case 1:
\end{large}
$s_1 \in [q_1,q_2]$ and hence $q_1\leq s_1\leq q_2$.
in this case\\
$$cost_T(q_1,q_2|s_1)=\alpha\sum_{i=1}^2|q_i-s_1| = \alpha(s_1-q_1+q_2-s_1)=\alpha(q_2-q_1)$$\\
from above it is concluded that the cost of running two queries $q_1$ and $q_2$ when snapshot is placed between them is equal to the deviation between two queries.\\
\begin{large}
	case 2:
\end{large}
$s_1 \notin [q_1,q_2]$ and $s_1 < q_1 < q_2$. for this case the cost could be calculated as follows:
$$cost_T(q_1,q_2|s_1)=\alpha\sum_{i=1}^2|q_i-s_1| = \alpha(q_1-s_1+q_2-s_1)=\alpha(q_1+q_2-2s_1) $$$$>\alpha(q_1+q_2-2q_1)=\alpha(q_2-q_1)$$\\
Therefore we conclude that if the snapshot $s_1$ is placed before queries $q_1$ and $q_2$, the cost to perform both queries is greater than when the snapshot is placed between the two queries.\\
\begin{large}
	case 3:
\end{large}
$s_1 \notin [q_1,q_2]$ and $q_1 < q_2 < s_1$.
$$cost_T(q_1,q_2|s_1)=\alpha\sum_{i=1}^2|q_i-s_1| = \alpha(s_1-q_1+s_1-q_2)=\alpha(2s_1-q_1-q_2) $$$$>\alpha(2q_2-q_1-q_2)=\alpha(q_2-q_1)$$\\
hence, if the snapshot $s_1$ is placed after the two queries $q_1$ and $q_2$, then the cost of performing those queries are greater than when the snapshot is placed between them.\\
After examining case1, case2 and case3, we can conclude that the optimal place where we can place the snapshot $s_1$ to perform two queries $q_1$ and $q_2$, where $T(q_2)>T(q_1)$ is when $s_1 \in [q_1,q_2]$ which the cost is equal to $\alpha(q_2-q_1)$.\\
\\
Now consider the situation in which there are a set of queries $Q=\{q_1,q_2,...,q_n\}$ performed on the timeline. to choose the most optimal place to put the single snapshot $s_1$ in order to decrease the cost of queries, we should breakdown the set of queries into the set of intervals $[q_1,q_n],[q_2,q_{n-1}],...,[q_i,q_{n+1-i}]$ where n is the number of queries on timeline and $i=0,1,2,...,c$ where $c=\frac{n+1}{2}$ when there are odd number of queries and $c=\frac{n}{2}$ when there are even number of queries performed on the timeline.\\ based on the theory that we proved earlier, if we choose our snapshot $s_1$ in a place which $s_1\in[q_1,q_n],[q_2,q_{n-1}],...,[q_i,q_{n+1-i}]$, the cost of queries is minimized and this place seems to be the median of queries positions. The placement of snapshot $s_1$ in the median position of queries, make the cost of queries to be calculated as follows.
$$cost(q_1,q_2,...,q_n|s_1)=\alpha\sum_{i=1}^n |q_i-s_1| = $$
$$\alpha[(|q_1-s_1|+|q_n-s_1|)+(|q_2-s_1|+|q_{n-1}-s_1|)+...+|q_c-s_1|+|q_{n+1-c}-s_1|)]=$$
$$\alpha[(s_1-q_1+q_n-s_1)+(s_1-q_2+q_{n-1}-s_1)+...+(s_1-q_c+q_{n+1-c}-s_1)]=$$
$$\alpha[(q_n-q_1)+(q_{n-1}-q_2)+...+(q_{n+1-c}-q_c)]$$\\
Where parenthesis indicate the deviation from endpoints for one of nested intervals. Since the snapshot $s_1$ is inside each of these nested intervals, based on the theorem that we proved earlier, the sum within each set of intervals is minimized and therefore the total sum of absolute deviation is also minimized. In the case when there are odd number of queries performed on the timeline, the innermost interval is $[q_{\frac{n+1}{2}},q_{\frac{n+1}{2}}]$ and the position of $q_{\frac{n+1}{2}}$ is the optimal position to place snapshot $s_1$. also when there are even number of queries the innermost interval is $[q_{\frac{n}{2}},q_{\frac{n}{2}+1}]$, therefore if we choose snapshot $s_1$'s position to be at $q_{\frac{n}{2}}\leq s_1\leq q_{\frac{n}{2}+1}$,it guarantees that the snapshot exists inside each of nested intervals, and hence the sum of absolute deviation is minimized. 



\section{Applying cryptography}
\subsection{Signing}
\subsection{Signature validation}
\section{Blockchain}
\subsection{Creating Blocks}
\subsection{Block Validation}
\subsection{report fake data}

