\chapter{Motivation and Problem Definition} \label{ch:motivation}

	\section{Motivation} \label{sec:motivation}
		Historical data is widely analysed for a lot of purposes such as making data-driven decisions \cite{rose2016datascience}. Historical data could be financial reports, project data, emails, audit logs or any similar documents which contain past occurrences in an organization.

		Historical data of a database provides data provenance which makes it possible to investigate the origin, the cause and the time of the processes that made changes to the tables and records ever exsisted in a database \cite{cheney2009provenance}. This data could be collected by auditing all the transactions that occur on a database system and store them in a logfile \cite{ghoshal2013provenance}. Although in large database systems, storing these historical data could seem burdensome and impractical due to the size they may get into \cite{crosby2009tamper-evident}, but current big data technologies such as cloud storages has made it possible to store these information in an easier and more affordable way than before \cite{talia2015dataanalysis}. In practice, not only these logfiles are useful assets that could be analyzed to detect maliciously manipulated data by outsider adversaries, but they can also give a valuable insight into the activities of the privileged users on a database system \cite{sinha2014continuous}.

		Utilizing logfiles as the source of data provenance gives us a useful tool to establish a trustworthy database environment \cite{viglas2013DataProvenance}, however this requires to make sure that the records in the logfile are trusted themselves \cite{Dai2008anapproach}.The challenge is that these files are not immune from being compromised \cite{wagner2018detect}\cite{lin2015secure}. In fact, not only the inherent security tools of most of the database management systems including the relational database management system (RDBMS) has proven to be vulnearable to complex cyber-security attacks \cite{wanger2017carving}, but also the malicious activities of the insiders who can bypass all the security requirements can add up to the complexity of the problem \cite{wagner2018detect}.

		For a better understanding of the complexity of malicious attacks on the log files, consider a scenario in which a database super-user who acts as root can perform a lot of administrative tasks on a relational database. Since the super-user can bypass all the security requirements, they can remove the trace of their malicious activities from the log file. Such attempts results in the maliciously altered data in the database that are hard to identify because there are no evidences to contradict their legitimacy.
		
		The afformentioned example clearly proves that restricting the activities of the users or utilizing preventive security tools for the database system cannot guarantee that the records will always remain trustworthy. Therefore, there is a need of a mechanism that makes the complexity of creating undetectable forgeries on the data provenance sources extremely expensive and unimaginable for all the users regardless of their level of accessibility to the system. The system should also be able to detect any malicious or accidental data manipulation on the database solely by relying on the verifiable evidences.

		Our objective is to design a mechanism based on relational database management system that provides trustworthy logfiles that are used as the source of data provenance of the database system. To achieve the objective of both providing trusted data and a functional system, we argue that the following requirements need to be addressed.

		\begin{itemize}
			  \item \textbf{\textit{Immutability of the records:}} To make sure that the a record in a relational database is trustworthy, performing undetectable malicious modification on that record should be extremely expensive. That is, any malicious or accidental attempts to modify the records stored in a database should result in an evident inconsistency in the data stored.

			  \item \textbf{\textit{Verifiability of trustworthiness:}} For all the records that are submitted in a database system, the origin of that transaction as well as the ligitimacy of the origin should be investigatbale using the verifiable evidences .

			  \item \textbf{\textit{Fast querying:}} The tables that contain historical records can become extremely large, and as a result, querying on these tables and verifying the trustworthiness of the result of queries can become inefficient \cite{crosby2009tamper-evident}\cite{beirami2018snapshot}. For the system to be functional, a mechanism should be implemented in order to reduce the cost of both answeing to the queries and verifying the trustworthiness of the query results.

			  \item \textbf{\textit{Fast appending:}} The system needs to collect all the security information of the transactions and append them to the logfile in an immutable way. In order to create a functional system, this process should be done as cheap as possible.
	\end{itemize}
		In this thesis, our research is focused on the relational databases that are as open and as scalable as possible. We assume that the adversaries are present and do malicious activities on the network, however our goal is to make their attempt to forge the records extremely expensive and evident. We believe that our proposed system is powerful in the sense that it removes the user-based trust and testifies the credibility or invalidity of the records by analyzing verifiable evidences. The system is able to detect privileged database misuses such as altering the auditing mechanism or manipulating the historical data. Our system utilizes many native to RDBMS tools such as relational temporal tables to store the historical data and cryptographic techniques to make transactions immutable and verifiable, therefore it could be supported by all RDBMSes available today with least additional requirements.

