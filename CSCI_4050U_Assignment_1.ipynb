{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CSCI 4050U Assignment 1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kenpu-uoit/beirami-thesis/blob/master/CSCI_4050U_Assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhUDtRePLGg-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hx4vs_JELYzq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as pl"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Igj2H6SVMQfu",
        "colab_type": "text"
      },
      "source": [
        "# Classification of flowers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdAwS_f2Mnhl",
        "colab_type": "text"
      },
      "source": [
        "## The Dataset: Iris classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEoMdoS9MtGR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "iris = load_iris()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6OCx563NXma",
        "colab_type": "text"
      },
      "source": [
        "We have 150 samples which are the measurements of three different types of the _iris_ flower.\n",
        "\n",
        "Each sample consists of four measurements.  They correspond to the dimensions of (length and width) of different parts of the flower.\n",
        "\n",
        "The features are stored in a tensor `X` with shape (150, 4).\n",
        "\n",
        "Each sample also has an integer (0, 1, 2) that indicates the species of the sample: (0: setosa, 1: versicolor, 2: virginica).  We use one-hot encoding.  Namely, we have:\n",
        "\n",
        "$$\\begin{eqnarray}\n",
        "\\mathrm{enc}(0) &=& [1, 0, 0] \\\\\n",
        "\\mathrm{enc}(1) &=& [0, 1, 0] \\\\\n",
        "\\mathrm{enc}(2) &=& [0, 0, 1] \\\\\n",
        "\\end{eqnarray}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EtVTA3nMvrp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ---------------------\n",
        "# Load the data\n",
        "# ---------------------\n",
        "n_samples = len(iris.data)\n",
        "n_species = len(iris.target_names)\n",
        "X = tf.constant(iris.data, dtype=tf.float64)\n",
        "\n",
        "I = iris.target\n",
        "Y = np.zeros((n_samples, n_species))\n",
        "Y[np.arange(n_samples), I] = 1\n",
        "Y = tf.constant(Y, dtype=tf.float64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XL2Y7r2o_TWC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# --------------------------\n",
        "# Inspect the data\n",
        "# --------------------------\n",
        "print(\"Features of first ten samples.\")\n",
        "print(X[:10, :])\n",
        "print()\n",
        "print(\"Species as one-hot vectors\")\n",
        "print(Y[:10, :])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IEHecA0MzNk",
        "colab_type": "text"
      },
      "source": [
        "## Multi-class logistic regression.\n",
        "\n",
        "Consider the feature vector $x\\in\\mathbf{R}^4$ of a single sample.  You need to build a model that predicts the species as a probability distribution $p = [p_0, p_1, p_2] \\in\\mathbf{R}^3$.\n",
        "\n",
        "In order to build the model, we will need two _transformations_ applied to $x$.\n",
        "\n",
        "### Linear transformation\n",
        "---\n",
        "\n",
        "$$ z = W\\cdot x + b $$\n",
        "where $W\\sim (3, 4)$ and $b\\sim(1, 3)$\n",
        "\n",
        "The linear transformation produces a vector $z\\in\\mathbf{R}^3$.  This is known as the _logit_ vector.\n",
        "\n",
        "#### Batch processing\n",
        "When we have a batch of samples $X\\sim(150, 4)$, we can perform\n",
        "the linear transformation as:\n",
        "\n",
        "$$ Z = X\\cdot W^T + b $$\n",
        "where $Z\\sim (150, 3)$.\n",
        "\n",
        "### Softmax transformation\n",
        "---\n",
        "\n",
        "Next we will map the logit vector to a proper probability distribution.  This is done by taking the exponentiation of each $z_i$, and renormalize by the sum.\n",
        "\n",
        "$$ p_i = \\frac{\\exp(z_i)}{\\sum_{k=0}^2 \\exp(z_i)} $$\n",
        "\n",
        "This is known as the _softmax_ transformation:\n",
        "\n",
        "$$ p = \\mathrm{softmax}(z) $$\n",
        "\n",
        "### The final model\n",
        "---\n",
        "\n",
        "Together, we have the following model:\n",
        "\n",
        "$$ \\mathrm{model}(X|\\theta) = \\mathrm{softmax}\\left(X\\cdot W^T + b\\right) $$\n",
        "\n",
        "The model parameter $\\theta = (W, b)$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCPGOukZEKmc",
        "colab_type": "text"
      },
      "source": [
        "_Hint_\n",
        "\n",
        "Tensorflow comes with a built-in softmax function:\n",
        "\n",
        "```python\n",
        "P = tf.nn.softmax(Z)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6yiA2hKVqNK",
        "colab_type": "text"
      },
      "source": [
        "**Implement the model function\n",
        "that accepts a batch of feature vectors, and\n",
        "returns the batch of probabilities.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAN_xWO8N4nc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model(X, theta):\n",
        "  # complete\n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJkzWDTvG6ts",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -------------------------------------\n",
        "# Testing your model\n",
        "# -------------------------------------\n",
        "W0 = tf.Variable(np.random.randn(3, 4))\n",
        "b0 = tf.Variable(np.random.randn(1, 3))\n",
        "\n",
        "P = model(X, [W0, b0])\n",
        "\n",
        "assert(P.shape == (150,3))\n",
        "assert(np.all(0 <= P))\n",
        "assert(np.all(P <= 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7O6loYGWcod",
        "colab_type": "text"
      },
      "source": [
        "## The loss function\n",
        "\n",
        "Once a prediction probability, $p = [p_0, p_1, p_2]$, is made by the model, but the true output is given by $y = [y_0, y_1, y_2]$, where only one $y_i = 1$.\n",
        "\n",
        "We measure the accuracy of the prediction using _cross entropy_ between $y$ and $p$, as defined as:\n",
        "\n",
        "$$\\mathrm{crossentropy}(y, p) = - \\sum_{i=0}^2 y_i\\cdot\\log(p_i)$$\n",
        "\n",
        "When a batch of prediction probabilities $Y$, and true categories $Y_\\mathrm{true}$ is given, the loss can be the mean average of the cross entropy:\n",
        "\n",
        "$$ \\mathrm{loss}(Y^\\mathrm{true}, Y)=\\frac{1}{n}\\sum_{i=1}^n\n",
        "\\mathrm{crossentropy}(y^\\mathrm{true}_i, y_i)$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcUKqI1_kllc",
        "colab_type": "text"
      },
      "source": [
        "**Implement the loss function that accepts as input:**\n",
        "\n",
        "1. A batch of the true categories in one-hot encoding.\n",
        "2. A batch of prediction probabilities.\n",
        "\n",
        "The loss function is to return a **single** scalar tensor as the loss.\n",
        "\n",
        "*Hint*:\n",
        "\n",
        "Tensorflow comes with a built-in cross-entropy loss function:\n",
        "\n",
        "```python\n",
        "tf.losses.categorical_crossentropy(Y_true, Y_pred)\n",
        "```\n",
        "\n",
        "which returns a tensor of losses with shape `(150,)`.  You will need to further reduce this to a scalar tensor using:\n",
        "\n",
        "```python\n",
        "tf.reduce_mean(...)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLr3aPlLlmfW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss(Y_true, Y_pred):\n",
        "  # complete\n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFlFWvlnTyBd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# --------------------------------\n",
        "# Test the loss function\n",
        "# --------------------------------\n",
        "\n",
        "assert(loss(Y, Y).shape == ())\n",
        "assert(loss(Y, Y).numpy() < 1E-5)\n",
        "\n",
        "assert(loss(Y, model(X, [W0, b0])) > 1E-5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bF7HM-PlpUI",
        "colab_type": "text"
      },
      "source": [
        "## Training by optimization\n",
        "\n",
        "Recall the objective is to perform model parameter estimation to minimize the loss.  This is done with gradient descent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fKC0DdJ8DMi",
        "colab_type": "text"
      },
      "source": [
        "**Implement a generic _train_ function as follows.**\n",
        "\n",
        "**Input arguments**\n",
        "\n",
        "1. model: a model function\n",
        "2. theta: a list of tensorflow variables which will be the model parameters\n",
        "3. loss: a loss function\n",
        "4. X: a batch of inputs\n",
        "5. Y: a batch of true outputs\n",
        "6. epochs: the _total_ number of epochs to run\n",
        "7. alpha: the learning rate\n",
        "\n",
        "**Output**\n",
        "\n",
        "- A _numpy array_ of shapes `(epochs,)` which represents the loss _after_ each epochs.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJi8v_wR6Lxq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, theta, loss, X, Y, epochs, alpha):\n",
        "  # complete\n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uO1dRmyO-TBY",
        "colab_type": "text"
      },
      "source": [
        "**Choose the epochs and learning rate accordingly**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNVPmJoiVPq8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = # complete\n",
        "alpha = # complete"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIaguavFWCvX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ---------------------------\n",
        "# Testing training loss\n",
        "# ---------------------------\n",
        "\n",
        "assert(training_losses.shape == (epochs,))\n",
        "\n",
        "# Make sure the training loss is sufficient\n",
        "assert(training_losses[-1] < 0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ARRxNdWJ6p_",
        "colab_type": "text"
      },
      "source": [
        "# Accuracy\n",
        "\n",
        "To see how the model can predict the species, we will evaluate the accuracy as the percentage of _correct_ prediction.\n",
        "\n",
        "Suppose that we have a prediction `Y_pred` as probabilities of shape `(150,3)`.\n",
        "We can use the Numpy argmax to find the index with the greatest probability.\n",
        "\n",
        "```python\n",
        "I_pred = np.argmax(Y_pred, axis=1)\n",
        "```\n",
        "\n",
        "where `I_pred` has a shape of `(150,)`.  We can compute the percentage of _correct_ guesses by element comparison with `I_true` and then count the number of `1`s using `np.sum(...)`.\n",
        "\n",
        "```python\n",
        "total_correct = np.sum(I_true == I_pred)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_lqT9yEQT_C",
        "colab_type": "text"
      },
      "source": [
        "**Implement a function `evaluate` that will evaluate the accuracy of a model with respect to a given model parameter `theta`** . \n",
        "\n",
        "**Input parameters**\n",
        "\n",
        "1. model: a model to be evaluated\n",
        "2. theta: the model parameter to use\n",
        "3. X: a batch of input\n",
        "4. I_true: the true categories (as integers) for the batch of input\n",
        "\n",
        "**Output**\n",
        "\n",
        "- An float number between 0 and 1.0 which is the pecentage of _correct_ guesses by the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ekEBrjtOmIx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, theta, X, I_true):\n",
        "  # complete\n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94MaMKsGPKSx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ----------------------------------\n",
        "# Test the accuracy\n",
        "# ----------------------------------\n",
        "\n",
        "accuracy = evaluate(model, [W, b], X, I)\n",
        "print(\"Accuracy: %.2f %%\" % (accuracy * 100))\n",
        "\n",
        "assert(accuracy.shape == ())\n",
        "assert(0.90 < accuracy <= 1.0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKZS0vW2X79-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}